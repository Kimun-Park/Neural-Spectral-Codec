\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{kotex}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{algorithm2e}
\usepackage{booktabs}

\geometry{a4paper, margin=2.5cm}

\newtheorem{definition}{Definition}
\newtheorem{notation}{Notation}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\FFT}{FFT}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\SE}{SE}
\DeclareMathOperator{\SO}{SO}

\title{Formal Specification:\\GNN-based LiDAR SLAM System}
\author{}
\date{}

\begin{document}

\maketitle

\section{FFT-based Descriptor}

\subsection{Point Cloud Representation}

\begin{definition}[LiDAR Point Cloud]
A LiDAR point cloud is defined as a finite set of 3D points:
\begin{equation}
\mathcal{P} = \{p_i \in \mathbb{R}^3 : i = 1, \ldots, N_p\}
\end{equation}
where $N_p$ is the number of points in the scan.
\end{definition}

\begin{definition}[Spherical Coordinate Transformation]
Each point $p_i = (x_i, y_i, z_i)^T$ is converted to spherical coordinates $(r_i, \theta_i, \phi_i)$ where:
\begin{align}
r_i &= \sqrt{x_i^2 + y_i^2 + z_i^2} \\
\theta_i &= \arctan2(y_i, x_i) \in [0, 2\pi) \quad \text{(azimuth)} \\
\phi_i &= \arcsin\left(\frac{z_i}{r_i}\right) \in [-\pi/2, \pi/2] \quad \text{(elevation)}
\end{align}
\end{definition}

\subsection{Spherical Binning}

\begin{definition}[Elevation Binning]
The elevation angle space is discretized into $r$ bins:
\begin{equation}
\mathcal{B}_{\phi} = \{B_0^{\phi}, B_1^{\phi}, \ldots, B_{r-1}^{\phi}\}
\end{equation}
where each bin $B_j^{\phi}$ corresponds to an elevation range:
\begin{equation}
B_j^{\phi} = \left[\phi_{\min} + j \cdot \Delta\phi, \phi_{\min} + (j+1) \cdot \Delta\phi\right)
\end{equation}
with $\Delta\phi = \frac{\phi_{\max} - \phi_{\min}}{r}$.
\end{definition}

\begin{definition}[Azimuth Binning]
The azimuth angle space $[0, 2\pi)$ is discretized into $k$ bins:
\begin{equation}
\mathcal{B}_{\theta} = \{B_0^{\theta}, B_1^{\theta}, \ldots, B_{k-1}^{\theta}\}
\end{equation}
where each bin $B_\ell^{\theta}$ corresponds to an azimuth range:
\begin{equation}
B_\ell^{\theta} = \left[\ell \cdot \Delta\theta, (\ell+1) \cdot \Delta\theta\right)
\end{equation}
with $\Delta\theta = \frac{2\pi}{k}$.
\end{definition}

\begin{definition}[2D Spherical Grid]
The point cloud is projected onto a 2D spherical grid $S \in \mathbb{R}^{r \times k}$ where each cell $(j, \ell)$ aggregates points:
\begin{equation}
S[j, \ell] = \text{agg}\{r_i : p_i \in \mathcal{P}, \phi_i \in B_j^{\phi}, \theta_i \in B_\ell^{\theta}\}
\end{equation}
where $\text{agg}(\cdot)$ is an aggregation function (e.g., mean range, max intensity, or point count).

Each row of $S$ corresponds to a ring at a specific elevation:
\begin{equation}
\mathbf{s}_j = [S[j, 0], S[j, 1], \ldots, S[j, k-1]]^T \in \mathbb{R}^k
\end{equation}
\end{definition}

\subsection{Frequency Domain Transformation}

\begin{definition}[Ring-wise FFT]
For each ring signal $\mathbf{s}_j \in \mathbb{R}^k$, we apply the Discrete Fourier Transform:
\begin{equation}
\mathbf{F}_j = \FFT(\mathbf{s}_j) \in \mathbb{C}^k
\end{equation}
where the $m$-th frequency component is:
\begin{equation}
F_j[m] = \sum_{\ell=0}^{k-1} s_j[\ell] \cdot e^{-i 2\pi m\ell / k}, \quad m = 0, \ldots, k-1
\end{equation}
\end{definition}

\begin{definition}[Magnitude Spectrum]
Due to Hermitian symmetry of real signals, we retain only the non-negative frequencies and extract the magnitude spectrum:
\begin{equation}
\mathbf{M}_j = [|F_j[0]|, |F_j[1]|, \ldots, |F_j[K]|]^T \in \mathbb{R}^{K+1}
\end{equation}
where $K = \lfloor k/2 \rfloor$, yielding rotation-invariant features.
\end{definition}

\subsection{Frequency Sampling}

\begin{definition}[Sampling Policy]
A sampling policy is a function $\sigma: \{0, 1, \ldots, K\} \rightarrow \{0, 1\}$ that selects a subset of $n$ frequencies:
\begin{equation}
\mathcal{I} = \{m \in \{0, \ldots, K\} : \sigma(m) = 1\}, \quad |\mathcal{I}| = n
\end{equation}

Common policies include:
\begin{itemize}
    \item \textbf{Uniform}: $\mathcal{I} = \{0, \Delta, 2\Delta, \ldots\}$ where $\Delta = \lceil K/n \rceil$
    \item \textbf{Log-scale}: $\mathcal{I} = \{\lfloor \log_2(m+1) \cdot c \rfloor : m = 0, \ldots, n-1\}$
    \item \textbf{Learned}: $\sigma$ is optimized via feature selection algorithms
\end{itemize}
\end{definition}

\begin{definition}[Sampled Descriptor per Ring]
For ring $j$, the sampled feature vector is:
\begin{equation}
\mathbf{d}_j = [M_j[i_0], M_j[i_1], \ldots, M_j[i_{n-1}]]^T \in \mathbb{R}^n
\end{equation}
where $\mathcal{I} = \{i_0, i_1, \ldots, i_{n-1}\}$ with $i_0 < i_1 < \cdots < i_{n-1}$.
\end{definition}

\subsection{Final Descriptor}

\begin{definition}[FFT-based Place Descriptor]
The final descriptor for point cloud $\mathcal{P}$ is the concatenation of all ring descriptors:
\begin{equation}
\mathbf{d}(\mathcal{P}) = [\mathbf{d}_0^T, \mathbf{d}_1^T, \ldots, \mathbf{d}_{r-1}^T]^T \in \mathbb{R}^{r*n}
\end{equation}

This maps a point cloud to a fixed-dimensional feature vector:
\begin{equation}
\mathbf{d}: \mathcal{P} \rightarrow \mathbb{R}^D, \quad D = r*n
\end{equation}
\end{definition}

\section{Pose Graph Structure}

\subsection{Graph Definition}

\begin{definition}[Pose Graph]
A pose graph is a tuple $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ where:
\begin{itemize}
    \item $\mathcal{V} = \{v_0, v_1, \ldots, v_{N-1}\}$ is the set of vertices (keyframes)
    \item $\mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}$ is the set of edges (spatial constraints)
\end{itemize}
with $|\mathcal{V}| = N$ keyframes.
\end{definition}

\subsection{Vertex Attributes}

\begin{definition}[Vertex Attributes]
Each vertex $v_i \in \mathcal{V}$ is associated with the following attributes:
\begin{equation}
v_i = (\mathcal{P}_i, \mathbf{d}_i, T_i, \mathbf{h}_i, t_i)
\end{equation}
where:
\begin{itemize}
    \item $\mathcal{P}_i$: Point cloud at keyframe $i$
    \item $\mathbf{d}_i \in \mathbb{R}^D$: FFT descriptor
    \item $T_i \in \SE(3)$: Robot pose in world frame
    \item $\mathbf{h}_i \in \mathbb{R}^{d'}$: GNN embedding (learned representation)
    \item $t_i \in \mathbb{R}_{\geq 0}$: Timestamp
\end{itemize}
\end{definition}

\begin{definition}[Special Euclidean Group]
The pose $T_i \in \SE(3)$ is a rigid body transformation:
\begin{equation}
\SE(3) = \left\{ T = \begin{bmatrix} R & \mathbf{t} \\ \mathbf{0}^T & 1 \end{bmatrix} : R \in \SO(3), \mathbf{t} \in \mathbb{R}^3 \right\}
\end{equation}
where $\SO(3)$ is the special orthogonal group (rotation matrices) and $\mathbf{t}$ is translation.
\end{definition}

\subsection{Edge Attributes}

\begin{definition}[Edge Attributes]
Each edge $e_{ij} = (v_i, v_j) \in \mathcal{E}$ represents a spatial constraint with attributes:
\begin{equation}
e_{ij} = (\Delta T_{ij}, \Omega_{ij}, \tau_{ij})
\end{equation}
where:
\begin{itemize}
    \item $\Delta T_{ij} \in \SE(3)$: Relative pose constraint from $v_i$ to $v_j$
    \item $\Omega_{ij} \in \mathbb{R}^{6 \times 6}$: Information matrix (inverse covariance)
    \item $\tau_{ij} \in \{\text{odometry}, \text{loop\_closure}\}$: Edge type
\end{itemize}
\end{definition}

\begin{definition}[Relative Pose Constraint]
The relative pose constraint $\Delta T_{ij}$ relates two poses via:
\begin{equation}
T_j = T_i \oplus \Delta T_{ij}
\end{equation}
where $\oplus$ denotes the $\SE(3)$ group operation (matrix multiplication).
\end{definition}

\begin{definition}[Information Matrix]
The information matrix quantifies the confidence in the relative pose measurement:
\begin{equation}
\Omega_{ij} = \Sigma_{ij}^{-1}
\end{equation}
where $\Sigma_{ij} \in \mathbb{R}^{6 \times 6}$ is the covariance matrix parameterized over the Lie algebra $\mathfrak{se}(3)$.

Typical structure:
\begin{equation}
\Omega_{ij} = \begin{bmatrix}
\Omega_{ij}^{trans} & \mathbf{0} \\
\mathbf{0} & \Omega_{ij}^{rot}
\end{bmatrix}
\end{equation}
where $\Omega_{ij}^{trans} \in \mathbb{R}^{3 \times 3}$ (translation) and $\Omega_{ij}^{rot} \in \mathbb{R}^{3 \times 3}$ (rotation).
\end{definition}

\subsection{Edge Types}

\begin{definition}[Odometry Edge]
An odometry edge connects sequential keyframes:
\begin{equation}
e_{i,i+1}^{odom} = (\Delta T_{odom}, \Omega_{odom}, \text{odometry})
\end{equation}
where $\Delta T_{odom}$ is measured from wheel encoders, IMU, or scan matching, and typically:
\begin{equation}
\Omega_{odom} = \diag(\omega_{x}, \omega_{y}, \omega_{z}, \omega_{\alpha}, \omega_{\beta}, \omega_{\gamma})
\end{equation}
with higher weights for more reliable degrees of freedom.
\end{definition}

\begin{definition}[Loop Closure Edge]
A loop closure edge connects non-sequential keyframes when revisiting a location:
\begin{equation}
e_{ij}^{LC} = (\Delta T_{LC}, \Omega_{LC}, \text{loop\_closure})
\end{equation}
where $|j - i| > \delta_{temporal}$ (temporal gap threshold), $\Delta T_{LC}$ is computed via ICP/GICP registration, and:
\begin{equation}
\Omega_{LC} = f_{quality}(\text{fitness}, \text{RMSE}) \cdot \Omega_{base}
\end{equation}
is scaled by registration quality.
\end{definition}

\section{GNN-Enhanced Graph}

\subsection{Adjacency Structure}

\begin{definition}[Adjacency Matrix]
The graph structure is encoded by an adjacency matrix $A \in \{0,1\}^{N \times N}$:
\begin{equation}
A[i,j] = \begin{cases}
1 & \text{if } (v_i, v_j) \in \mathcal{E} \text{ or } (v_j, v_i) \in \mathcal{E} \\
0 & \text{otherwise}
\end{cases}
\end{equation}
For undirected graphs, $A$ is symmetric.
\end{definition}

\begin{definition}[Normalized Adjacency]
For GCN propagation, we use the symmetrically normalized adjacency:
\begin{equation}
\tilde{A} = D^{-1/2} (A + I) D^{-1/2}
\end{equation}
where:
\begin{itemize}
    \item $I \in \mathbb{R}^{N \times N}$ is the identity matrix (self-connections)
    \item $D$ is the degree matrix: $D[i,i] = \sum_j (A[i,j] + I[i,j])$
\end{itemize}
\end{definition}

\subsection{Feature and Embedding Spaces}

\begin{definition}[Node Feature Matrix]
The initial node features are stacked as:
\begin{equation}
X = [\mathbf{d}_0, \mathbf{d}_1, \ldots, \mathbf{d}_{N-1}]^T \in \mathbb{R}^{N \times D}
\end{equation}
where row $i$ contains the FFT descriptor $\mathbf{d}_i$ for vertex $v_i$.
\end{definition}

\begin{definition}[GNN Embedding Function]
A Graph Neural Network defines a mapping:
\begin{equation}
f_{GNN}: \mathbb{R}^{N \times D} \times \mathbb{R}^{N \times N} \rightarrow \mathbb{R}^{N \times d'}
\end{equation}
that transforms node features $X$ given graph structure $A$ into embeddings:
\begin{equation}
H = f_{GNN}(X, A)
\end{equation}
where $H = [\mathbf{h}_0, \mathbf{h}_1, \ldots, \mathbf{h}_{N-1}]^T \in \mathbb{R}^{N \times d'}$.
\end{definition}

\subsection{Graph Convolutional Network}

\begin{definition}[Neighborhood]
For vertex $v_i$, its neighborhood is:
\begin{equation}
\mathcal{N}(v_i) = \{v_j \in \mathcal{V} : (v_i, v_j) \in \mathcal{E} \text{ or } (v_j, v_i) \in \mathcal{E}\}
\end{equation}
\end{definition}

\begin{definition}[Message Passing with Weighted Aggregation]
At each layer $\ell$, node $v_i$ updates its representation by aggregating features from itself and its neighbors:
\begin{equation}
\mathbf{h}_i^{(\ell+1)} = \sigma\left(W^{(\ell)}_{\text{self}} \mathbf{h}_i^{(\ell)} + \sum_{v_j \in \mathcal{N}(v_i)} \alpha_{ij}^{(\ell)} W^{(\ell)}_{\text{neigh}} \mathbf{h}_j^{(\ell)}\right)
\end{equation}
where:
\begin{itemize}
    \item $\mathbf{h}_i^{(\ell)} \in \mathbb{R}^{d_\ell}$: Feature of node $v_i$ at layer $\ell$
    \item $W^{(\ell)}_{\text{self}} \in \mathbb{R}^{d_{\ell+1} \times d_\ell}$: Weight matrix for self-feature
    \item $W^{(\ell)}_{\text{neigh}} \in \mathbb{R}^{d_{\ell+1} \times d_\ell}$: Weight matrix for neighbor features
    \item $\alpha_{ij}^{(\ell)} \in \mathbb{R}$: Aggregation weight for neighbor $v_j$
    \item $\sigma(\cdot)$: Non-linear activation (e.g., ReLU)
\end{itemize}
\end{definition}

\begin{definition}[Aggregation Weights]
The aggregation weights $\alpha_{ij}$ are determined by the graph structure. Common choices include:

\textbf{Uniform weighting} (GraphSAGE-mean):
\begin{equation}
\alpha_{ij} = \frac{1}{|\mathcal{N}(v_i)|}
\end{equation}

\textbf{Degree-normalized weighting} (GCN):
\begin{equation}
\alpha_{ij} = \frac{1}{\sqrt{d_i \cdot d_j}}
\end{equation}
where $d_i = |\mathcal{N}(v_i)| + 1$ (degree including self-loop).

\textbf{Learned attention} (GAT):
\begin{equation}
\alpha_{ij} = \frac{\exp(a(\mathbf{h}_i, \mathbf{h}_j))}{\sum_{v_k \in \mathcal{N}(v_i)} \exp(a(\mathbf{h}_i, \mathbf{h}_k))}
\end{equation}
where $a(\cdot, \cdot)$ is a learned attention function.
\end{definition}

\begin{definition}[Simplified GCN Form]
For computational efficiency, we use a single weight matrix with normalized aggregation:
\begin{equation}
\mathbf{h}_i^{(\ell+1)} = \sigma\left(W^{(\ell)} \left(\mathbf{h}_i^{(\ell)} + \sum_{v_j \in \mathcal{N}(v_i)} \alpha_{ij} \mathbf{h}_j^{(\ell)}\right)\right)
\end{equation}
where $\alpha_{ij} = \frac{1}{\sqrt{(|\mathcal{N}(v_i)|+1)(|\mathcal{N}(v_j)|+1)}}$.

This combines self-feature and neighbor features before transformation.
\end{definition}

\begin{definition}[L-layer GNN]
A Graph Neural Network with $L$ layers iteratively applies message passing:
\begin{align}
\mathbf{h}_i^{(0)} &= \mathbf{d}_i \quad \text{(initialize with descriptor)} \\
\mathbf{h}_i^{(\ell+1)} &= \sigma\left(W^{(\ell)} \left(\mathbf{h}_i^{(\ell)} + \sum_{v_j \in \mathcal{N}(v_i)} \alpha_{ij} \mathbf{h}_j^{(\ell)}\right)\right), \quad \ell = 0, \ldots, L-2 \\
\mathbf{h}_i^{(L)} &= W^{(L-1)} \left(\mathbf{h}_i^{(L-1)} + \sum_{v_j \in \mathcal{N}(v_i)} \alpha_{ij} \mathbf{h}_j^{(L-1)}\right) \quad \text{(final layer, no activation)}
\end{align}

The final embedding is $\mathbf{h}_i = \mathbf{h}_i^{(L)} \in \mathbb{R}^{d'}$.
\end{definition}

\begin{definition}[Receptive Field]
After $L$ layers of message passing, node $v_i$'s embedding $\mathbf{h}_i^{(L)}$ aggregates information from all nodes within $L$-hop distance:
\begin{equation}
\text{Receptive field of } v_i = \mathcal{N}_L(v_i) = \{v_j : d_G(v_i, v_j) \leq L\}
\end{equation}
where $d_G(\cdot, \cdot)$ is the shortest path distance in graph $\mathcal{G}$.
\end{equation}

\textbf{Example}: For $L=2$ layers:
\begin{itemize}
    \item Layer 1: $\mathbf{h}_i^{(1)}$ aggregates from 1-hop neighbors
    \item Layer 2: $\mathbf{h}_i^{(2)}$ aggregates from 2-hop neighbors (through layer 1)
\end{itemize}
\end{definition}

\begin{definition}[Matrix Form (Vectorized)]
For the entire graph, the update can be written in matrix form:
\begin{equation}
H^{(\ell+1)} = \sigma\left(\tilde{A} H^{(\ell)} W^{(\ell)}\right)
\end{equation}
where:
\begin{itemize}
    \item $H^{(\ell)} = [\mathbf{h}_1^{(\ell)}, \ldots, \mathbf{h}_N^{(\ell)}]^T \in \mathbb{R}^{N \times d_\ell}$
    \item $\tilde{A} = D^{-1/2}(A + I)D^{-1/2}$ is the normalized adjacency with self-loops
    \item $D$ is the degree matrix: $D[i,i] = \sum_j (A[i,j] + I[i,j])$
\end{itemize}

This is equivalent to the node-wise formulation but allows efficient parallel computation.
\end{definition}

\subsection{Local Update for Scalability}

\begin{definition}[N-hop Neighborhood]
For a vertex $v_i$, its $N$-hop neighborhood is:
\begin{equation}
\mathcal{N}_N(v_i) = \{v_j \in \mathcal{V} : d_G(v_i, v_j) \leq N\}
\end{equation}
where $d_G(v_i, v_j)$ is the shortest path distance in $\mathcal{G}$.
\end{definition}

\begin{definition}[Induced Subgraph]
The subgraph induced by vertex set $\mathcal{V}_{sub} \subseteq \mathcal{V}$ is:
\begin{equation}
\mathcal{G}_{sub} = (\mathcal{V}_{sub}, \mathcal{E}_{sub})
\end{equation}
where $\mathcal{E}_{sub} = \{(v_i, v_j) \in \mathcal{E} : v_i, v_j \in \mathcal{V}_{sub}\}$.
\end{definition}

\begin{definition}[Local GCN Update]
Upon inserting keyframe $v_k$, we update embeddings only for:
\begin{equation}
\mathcal{V}_{affected} = \mathcal{N}_N(v_k)
\end{equation}

The local update computes:
\begin{equation}
H_{sub} = f_{GNN}(X_{sub}, A_{sub})
\end{equation}
where $X_{sub}, A_{sub}$ are the feature matrix and adjacency of $\mathcal{G}_{sub} = (\mathcal{V}_{affected}, \mathcal{E}_{sub})$.

Complexity: $O(|\mathcal{V}_{affected}| \cdot L \cdot d^2)$ vs. $O(N \cdot L \cdot d^2)$ for full update.
\end{definition}

\section{Loop Closure Detection}

\begin{definition}[Similarity Function]
Given embeddings $\mathbf{h}_i, \mathbf{h}_j \in \mathbb{R}^{d'}$, we define similarity as:
\begin{equation}
\text{sim}(\mathbf{h}_i, \mathbf{h}_j) = \frac{\mathbf{h}_i^T \mathbf{h}_j}{\|\mathbf{h}_i\| \cdot \|\mathbf{h}_j\|} \in [-1, 1]
\end{equation}
(cosine similarity).
\end{definition}

\begin{definition}[Loop Closure Candidates]
For query keyframe $v_q$, the set of loop closure candidates is:
\begin{equation}
\mathcal{C}(v_q) = \left\{ v_i \in \mathcal{V} : |i - q| > \delta_{temp} \text{ and } \text{sim}(\mathbf{h}_q, \mathbf{h}_i) > \tau_{LC} \right\}
\end{equation}
where:
\begin{itemize}
    \item $\delta_{temp}$: Temporal gap threshold (e.g., 30 keyframes)
    \item $\tau_{LC} \in [0,1]$: Loop closure similarity threshold
\end{itemize}

Top-$K$ candidates:
\begin{equation}
\mathcal{C}_K(v_q) = \argmax_{S \subset \mathcal{C}(v_q), |S|=K} \sum_{v_i \in S} \text{sim}(\mathbf{h}_q, \mathbf{h}_i)
\end{equation}
\end{definition}

\section{Pose Graph Optimization}

\begin{definition}[Error Function]
For an edge $e_{ij}$ with constraint $\Delta T_{ij}$ and information $\Omega_{ij}$, the error is:
\begin{equation}
\mathbf{e}_{ij}(T_i, T_j) = \log\left(\Delta T_{ij}^{-1} \oplus (T_i^{-1} \oplus T_j)\right)^\vee \in \mathbb{R}^6
\end{equation}
where $\log: \SE(3) \rightarrow \mathfrak{se}(3)$ is the logarithm map and $(\cdot)^\vee$ converts to vector form.
\end{definition}

\begin{definition}[Optimization Problem]
The pose graph optimization problem is:
\begin{equation}
T^* = \argmin_{T_0, \ldots, T_{N-1}} \sum_{(v_i, v_j) \in \mathcal{E}} \mathbf{e}_{ij}^T \Omega_{ij} \mathbf{e}_{ij}
\end{equation}
subject to $T_0 = I$ (fix first pose).

This is solved via iterative non-linear least squares (e.g., Gauss-Newton, Levenberg-Marquardt).
\end{definition}

\section{Summary of Notation}

\begin{table}[h]
\centering
\begin{tabular}{cl}
\toprule
Symbol & Description \\
\midrule
$\mathcal{P}$ & Point cloud \\
$\mathbf{d} \in \mathbb{R}^D$ & FFT descriptor, $D = r*n$ \\
$\mathcal{G} = (\mathcal{V}, \mathcal{E})$ & Pose graph \\
$v_i = (\mathcal{P}_i, \mathbf{d}_i, T_i, \mathbf{h}_i, t_i)$ & Vertex (keyframe) \\
$e_{ij} = (\Delta T_{ij}, \Omega_{ij}, \tau_{ij})$ & Edge (constraint) \\
$T_i \in \SE(3)$ & Pose (4$\times$4 transformation matrix) \\
$\mathbf{h}_i \in \mathbb{R}^{d'}$ & GNN embedding \\
$A \in \{0,1\}^{N \times N}$ & Adjacency matrix \\
$\tilde{A}$ & Normalized adjacency \\
$f_{GNN}(X, A)$ & Graph Neural Network \\
$\Omega \in \mathbb{R}^{6 \times 6}$ & Information matrix \\
$\mathcal{N}_N(v_i)$ & N-hop neighborhood \\
\bottomrule
\end{tabular}
\caption{Summary of mathematical notation}
\end{table}

\end{document}
